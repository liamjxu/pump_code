{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb62c08-519b-417f-bad5-1b63310625ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T05:22:06.736314Z",
     "iopub.status.busy": "2024-07-12T05:22:06.735974Z",
     "iopub.status.idle": "2024-07-12T05:22:09.570592Z",
     "shell.execute_reply": "2024-07-12T05:22:09.569907Z",
     "shell.execute_reply.started": "2024-07-12T05:22:06.736291Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American_Trends_Panel_W26',\n",
       " 'American_Trends_Panel_W27',\n",
       " 'American_Trends_Panel_W29']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/mnt/sagemaker-nvme/cache'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import trange, tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from utils import last_token_pool, get_detailed_instruct, get_llm_response, PersonaDimension, list_s3_prefix\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from dataclasses import asdict\n",
    "\n",
    "surveys = set()\n",
    "for path in list_s3_prefix(\"human_resp/\"):\n",
    "    if path.startswith(\"human_resp/American_Trends_Panel\"):\n",
    "        # Extract the folder name\n",
    "        folder = path.split(\"/\")[1]\n",
    "        surveys.add(folder)\n",
    "surveys = sorted(list(surveys))[:3]\n",
    "surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aacf57-9ccd-4338-8319-4cf61795adfb",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b6196f-ea44-4aea-b547-08f536385a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T04:39:51.601372Z",
     "iopub.status.busy": "2024-07-12T04:39:51.600815Z",
     "iopub.status.idle": "2024-07-12T04:39:51.610730Z",
     "shell.execute_reply": "2024-07-12T04:39:51.610116Z",
     "shell.execute_reply.started": "2024-07-12T04:39:51.601349Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_personas_extracted_from_questions(personas_from_questions_filename):\n",
    "    with open(personas_from_questions_filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    res = []\n",
    "    for entry in data:\n",
    "        if not entry['valid']: continue\n",
    "        for persona_dim in eval(entry['response']):\n",
    "            entry_dict = asdict(persona_dim)\n",
    "            input_dict = eval(entry['input_dict'])\n",
    "            entry_dict['original_question'] = input_dict['question'] + ' ' + input_dict['options']\n",
    "            res.append(entry_dict)\n",
    "    df = pd.DataFrame(res)\n",
    "    return df\n",
    "\n",
    "\n",
    "def cluster_extracted_personas(survey, extraction_dir, output_dir, num_clusters, print_result, tokenizer, model):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get data\n",
    "    personas_from_questions_filename = f\"{extraction_dir}/personas_extracted_from_question_{survey}.json\"\n",
    "    data = get_personas_extracted_from_questions(personas_from_questions_filename)\n",
    "\n",
    "    # Get formatted string for clustering\n",
    "    def get_formatted_persona_dim(row):\n",
    "        task = 'Given a persona dimension description, retrieve semantically similar persona dimension descriptions.'\n",
    "        persona = f\"{row['name']}: {row['description']}. Candidate values: {row['candidate_values']}\"\n",
    "        return get_detailed_instruct(task, persona)\n",
    "    data['formatted'] = data.apply(get_formatted_persona_dim, axis=1)\n",
    "\n",
    "    for level in ['high', 'mid', 'low']:\n",
    "        # Get subset and save artifacts\n",
    "        level_df = data[data['level']==level]\n",
    "        level_df.to_csv(f\"{output_dir}/{level}-level_personas_{survey}.csv\")\n",
    "        \n",
    "        # Get the embeddings\n",
    "        max_length = 4096\n",
    "        input_texts = level_df['formatted'].to_list()\n",
    "\n",
    "        embeddings = []\n",
    "        for text in input_texts:\n",
    "            batch_dict = tokenizer([text], max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch_dict)\n",
    "                embed = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])[0]\n",
    "            embeddings.append(embed)\n",
    "        embeddings = torch.stack(embeddings, axis=0)\n",
    "        print(embeddings.shape, len(input_texts))\n",
    "        \n",
    "        # Clustering the embeddings and save artifacts\n",
    "        clustering_model = KMeans(n_clusters=num_clusters)\n",
    "        clustering_model.fit(embeddings)\n",
    "        level_df['cluster'] = clustering_model.labels_\n",
    "        level_df = level_df.sort_values(by='cluster')\n",
    "        level_df.to_csv(f'{output_dir}/clustered_{level}_level_personas_{survey}.csv')\n",
    "\n",
    "        if print_result:\n",
    "            for idx in range(num_clusters):\n",
    "                print(idx)\n",
    "                for _, row in enumerate(level_df[level_df['cluster'] == idx]['formatted']):\n",
    "                    print(row.split('\\n')[1])\n",
    "                print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889f45cb-0717-4ec6-8d59-53ba80d3c554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T04:39:51.611925Z",
     "iopub.status.busy": "2024-07-12T04:39:51.611740Z",
     "iopub.status.idle": "2024-07-12T04:44:25.382980Z",
     "shell.execute_reply": "2024-07-12T04:44:25.382117Z",
     "shell.execute_reply.started": "2024-07-12T04:39:51.611906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([226, 4096]) 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([226, 4096]) 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      " 33%|███▎      | 1/3 [01:15<02:30, 75.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([199, 4096]) 199\n",
      "torch.Size([268, 4096]) 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([403, 4096]) 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      " 67%|██████▋   | 2/3 [02:57<01:31, 91.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([205, 4096]) 205\n",
      "torch.Size([223, 4096]) 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([305, 4096]) 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      "/tmp/ipykernel_30235/4183643238.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  level_df['cluster'] = clustering_model.labels_\n",
      "100%|██████████| 3/3 [04:14<00:00, 84.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([158, 4096]) 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/SFR-Embedding-2_R')\n",
    "model = AutoModel.from_pretrained('Salesforce/SFR-Embedding-2_R', device_map='auto')\n",
    "\n",
    "for survey in tqdm(surveys):\n",
    "    cluster_extracted_personas(survey,\n",
    "                               extraction_dir='sm_local/outputs/extraction',\n",
    "                               output_dir='sm_local/outputs/clustering',\n",
    "                               num_clusters=20,\n",
    "                               print_result=False,\n",
    "                               tokenizer=tokenizer,\n",
    "                               model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeeafe7-3f74-4ba5-b32e-fafbb8a11c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756f166-7bd1-4b56-9154-8cedc63ffada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a316ae-e5e4-4572-a544-7df686b1e834",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d15aa0-ca4b-4303-94d2-8e43e8930230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T04:44:25.403816Z",
     "iopub.status.busy": "2024-07-12T04:44:25.403594Z",
     "iopub.status.idle": "2024-07-12T04:44:25.412179Z",
     "shell.execute_reply": "2024-07-12T04:44:25.411478Z",
     "shell.execute_reply.started": "2024-07-12T04:44:25.403793Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_clustered_personas(prompt_name, survey, level, clustering_dir, output_dir, num_clusters, print_result):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get data\n",
    "    clustered_persona_filename = f\"{clustering_dir}/clustered_{level}_level_personas_{survey}.csv\"\n",
    "    data = pd.read_csv(clustered_persona_filename)\n",
    "    with open(f'prompts/{prompt_name}.txt') as f:\n",
    "        prompt_template = f.read()\n",
    "\n",
    "    # summarize\n",
    "    res = []\n",
    "    for idx in trange(num_clusters):\n",
    "        persona_cluster = []\n",
    "        for _, row in data[data['cluster'].astype(str) == str(idx)].iterrows():\n",
    "            persona = PersonaDimension(**row[['name', 'description', 'level', 'candidate_values']].to_dict())\n",
    "            persona_cluster.append(persona)\n",
    "        \n",
    "        prompt = prompt_template.format(persona_dimensions='[\\n' + ',\\n'.join(repr(dim) for dim in persona_cluster) + '\\n]')\n",
    "        response = get_llm_response(prompt, prefill='[')\n",
    "        response = '[' + response\n",
    "        \n",
    "        try:\n",
    "            response = eval(response)\n",
    "            for dim in response:\n",
    "                res.append(dim)\n",
    "\n",
    "            record_res = [str(dim) for dim in res]\n",
    "            summarized_clustered_personas_filename = f\"{output_dir}/summarized_{level}_level_personas_{survey}.json\"\n",
    "            with open(summarized_clustered_personas_filename, 'w') as f:\n",
    "                json.dump(record_res, f, indent=4)\n",
    "    \n",
    "            if print_result:\n",
    "                print(response)\n",
    "        except:\n",
    "            if print_result:\n",
    "                print(f\"cluster {idx} failed\")\n",
    "                print(response)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aad01f-3552-4b48-a9fc-5c54af5d5d1e",
   "metadata": {
    "execution": {
     "execution_failed": "2024-07-12T05:03:07.736Z",
     "iopub.execute_input": "2024-07-12T04:44:25.413560Z",
     "iopub.status.busy": "2024-07-12T04:44:25.413342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for survey in surveys:\n",
    "    for level in ['low', 'mid', 'high']:\n",
    "        summarize_clustered_personas(prompt_name=\"summarize_clustered_personas\",\n",
    "                                     survey=survey,\n",
    "                                     level=level,\n",
    "                                     clustering_dir='sm_local/outputs/clustering',\n",
    "                                     output_dir='sm_local/outputs/summarizing',\n",
    "                                     num_clusters=20,\n",
    "                                     print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f813be-de88-420d-9859-2c6087ed6e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efded4-6baa-4ff0-83a2-7631436ca88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df7ea3be-cea0-4e34-91b9-e3e6870da19d",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf02c00-92a2-4c04-9ad0-8d813b436cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T05:22:13.530252Z",
     "iopub.status.busy": "2024-07-12T05:22:13.529708Z",
     "iopub.status.idle": "2024-07-12T05:22:13.535874Z",
     "shell.execute_reply": "2024-07-12T05:22:13.535230Z",
     "shell.execute_reply.started": "2024-07-12T05:22:13.530228Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_summarized_personas(prompt_name, survey, level, summarizing_dir, output_dir, num_clusters, print_result):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get data\n",
    "    summarized_persona_filename = f\"{summarizing_dir}/summarized_{level}_level_personas_{survey}.json\"\n",
    "    with open(summarized_persona_filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    with open(f'prompts/{prompt_name}.txt') as f:\n",
    "        prompt_template = f.read()\n",
    "\n",
    "    # summarize\n",
    "    prompt = prompt_template.format(persona_dimensions='[\\n' + ',\\n'.join(repr(dim) for dim in data) + '\\n]')\n",
    "    response = get_llm_response(prompt, prefill='[', max_tokens=4096)\n",
    "    response = '[' + response\n",
    "\n",
    "    # validate\n",
    "    try:\n",
    "        eval(response)\n",
    "        cleaned_summarized_personas_filename = f\"{output_dir}/cleaned_{level}_level_personas_{survey}.json\"\n",
    "        with open(cleaned_summarized_personas_filename, 'w') as f:\n",
    "            json.dump(response, f, indent=4)\n",
    "        return response\n",
    "    except:\n",
    "        print(f'Cleaned result is not valid. Survey: {survey}, Level: {level}. Response:')\n",
    "        # print(response)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54ea1d-3a91-434c-90e1-a9bb55cf3a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for survey in surveys:\n",
    "    for level in tqdm(['low', 'mid', 'high']):\n",
    "        cleaned_personas = clean_summarized_personas(prompt_name=\"clean_summarized_personas\",\n",
    "                                                      survey=survey,\n",
    "                                                      level=level,\n",
    "                                                      summarizing_dir='sm_local/outputs/summarizing',\n",
    "                                                      output_dir='sm_local/outputs/cleaned',\n",
    "                                                      num_clusters=20,\n",
    "                                                      print_result=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7589fe-5f17-4b8d-ac20-acf135f936eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T05:36:27.469330Z",
     "iopub.status.busy": "2024-07-12T05:36:27.468854Z",
     "iopub.status.idle": "2024-07-12T05:36:27.494850Z",
     "shell.execute_reply": "2024-07-12T05:36:27.494249Z",
     "shell.execute_reply.started": "2024-07-12T05:36:27.469307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 518.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 561.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 590.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for survey in surveys:\n",
    "    for level in tqdm(['low', 'mid', 'high']):\n",
    "        with open(f'sm_local/outputs/cleaned/cleaned_{level}_level_personas_{survey}.json') as f:\n",
    "            json_string = json.load(f)\n",
    "        response = eval(json_string)\n",
    "\n",
    "        csv_res = []\n",
    "        for entry in response:\n",
    "            csv_res.append(asdict(entry))\n",
    "        df = pd.DataFrame(csv_res)\n",
    "        df.to_csv(f'sm_local/outputs/cleaned/cleaned_{level}_level_personas_{survey}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7f740-50da-4dd4-8383-b8375dd9c4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1bcd67a-2a74-480e-bcc9-72213535e0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T22:29:58.174737Z",
     "iopub.status.busy": "2024-07-11T22:29:58.174296Z",
     "iopub.status.idle": "2024-07-11T22:30:39.546329Z",
     "shell.execute_reply": "2024-07-11T22:30:39.545580Z",
     "shell.execute_reply.started": "2024-07-11T22:29:58.174714Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a46ae-42f8-431e-b12c-af15a0761f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4792c9-6bb4-49a1-a955-bd0a67f98106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007628e2-f7a9-4304-a15e-2d1405538fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf575eb-c80e-4412-835c-1abd683ab85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8299c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed813f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pump)",
   "language": "python",
   "name": "pump"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
