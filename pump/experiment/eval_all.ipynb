{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/code/pump_post_midterm/pump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get test_q_keys\n",
    "# import random\n",
    "# import pandas as pd\n",
    "# from src.utils import get_file_from_s3\n",
    "\n",
    "# survey_name = \"American_Trends_Panel_W34\"\n",
    "# random.seed(42)\n",
    "# survey_df = pd.read_csv(get_file_from_s3(f\"human_resp/{survey_name}/info.csv\"))\n",
    "# q_keys = list(survey_df['key'])\n",
    "# test_q_keys = random.choices(q_keys, k=5)\n",
    "\n",
    "# print(test_q_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from src.utils import TEST_KEY_MAPPING\n",
    "\n",
    "test_q_keys_mapping = TEST_KEY_MAPPING\n",
    "\n",
    "# test_q_keys_mapping = {\n",
    "#     \"American_Trends_Panel_W26\": ['GUNRESPNOKIDSB_W26', 'WORLDDANGER_W26', 'GUNIDENTITY_W26', 'REASONGUNC_W26', 'GUNRESPKIDSC_W26'],\n",
    "#     \"American_Trends_Panel_W27\": ['CAREGIV3A_W27', 'PREDICTA_W27', 'WORK3C_W27', 'CARS10D_W27', 'CAREGIV7_W27'],\n",
    "#     \"American_Trends_Panel_W29\": ['TRAITSD_W29', 'NOWSMK_NHIS_W29', 'HELPHURTE_W29', 'HELPHURTA_W29', 'GIRLSF2A_W29'],\n",
    "#     \"American_Trends_Panel_W32\": ['NEIGHINTERB_W32', 'SATLIFEC_W32', 'SUCCESSIMPA_W32', 'COMMIMPE_W32', 'GROWUPUSR_W32'],\n",
    "#     \"American_Trends_Panel_W34\": ['MED4A_W34', 'SCI2A_W34', 'FUD22_W34', 'EAT3H_W34', 'MED6D_W34']\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "survey_names = [\n",
    "    \"American_Trends_Panel_W26\",\n",
    "    # \"American_Trends_Panel_W27\",\n",
    "    # \"American_Trends_Panel_W29\",\n",
    "    # \"American_Trends_Panel_W32\",\n",
    "    # \"American_Trends_Panel_W34\"\n",
    "]\n",
    "\n",
    "def skip_exp(filename):\n",
    "    # # check sonnet vs haiku pred\n",
    "    # if 'v11' in filename: return True\n",
    "    # if ('0830' in filename and 'prompt2' in filename): return False\n",
    "    # if ('sonnetpred' in filename): return False\n",
    "    # return True\n",
    "\n",
    "    # # check prompts\n",
    "    # if 'haikupred' not in filename: return True\n",
    "    # # if 'v12' in filename and 'prompt2' in filename: return False\n",
    "    # if 'v11' in filename: \n",
    "    #     if 'prompt2' in filename: return False\n",
    "    #     if 'prompt3' in filename: return False\n",
    "    #     if 'prompt4' in filename: return False\n",
    "    # if 'v10' in filename and 'prompt2' in filename: return False\n",
    "    # return True\n",
    "\n",
    "    # # check runs\n",
    "    # if 'haikupred' not in filename: return True\n",
    "    # if '0831' in filename and 'prompt3' in filename: return False\n",
    "    # if 'v11' in filename:\n",
    "    #     if 'prompt3' in filename: return False\n",
    "    # if 'v10' in filename and 'prompt2' in filename: return False\n",
    "    # return True\n",
    "\n",
    "    # check known test\n",
    "    if 'v13' not in filename: return True\n",
    "\n",
    "\n",
    "def get_exp(filename):\n",
    "    if filename[-5:] == '.json': filename = filename[:-5]\n",
    "    # segs = ['history', 'demo', 'persona', 'v11', 'v10', 'prompt3', 'prompt4', 'run1', 'run2', 'run3']\n",
    "    segs = ['history', 'demo', 'persona', 'v13', 'prompt3']\n",
    "    exp_elements = [_ for _ in filename.split('_') if _ in segs]\n",
    "    final = '_'.join(exp_elements)\n",
    "    # print(filename, '->', final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "from src.utils import get_file_from_s3\n",
    "\n",
    "def get_full_results(survey_name):\n",
    "    res = {}\n",
    "    for filename in os.listdir(f'opinions_qa/output/{survey_name}/'):\n",
    "        if skip_exp(filename): continue\n",
    "        exp = get_exp(filename)\n",
    "        # exp = filename\n",
    "        if exp not in res:\n",
    "            res[exp] = []\n",
    "            \n",
    "        with open(f\"opinions_qa/output/{survey_name}/{filename}\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "        res[exp] += [f\"={sum([_['is_correct'] for _ in data])}/{len(data)}\", sum([_['is_correct'] for _ in data])/len(data)]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(res)\n",
    "    df = df[sorted(df.columns)]\n",
    "    df = df.transpose()\n",
    "\n",
    "    acc_df = df\n",
    "    acc_df = acc_df.rename(columns={0: \"acc_cnt\", 1: \"acc\"})\n",
    "    acc_df.sort_values(by='acc', ascending=False)\n",
    "\n",
    "\n",
    "    test_q_keys = test_q_keys_mapping[survey_name]\n",
    "    print(test_q_keys)\n",
    "    survey_df = pd.read_csv(get_file_from_s3(f\"human_resp/{survey_name}/info.csv\"))\n",
    "    sub_df = survey_df[survey_df['key'].isin(test_q_keys)]\n",
    "\n",
    "    wd_question_mappings = {row['key']: dict(zip(eval(row['references'].lower()), eval(row['option_ordinal']))) for _, row in sub_df.iterrows()}\n",
    "    wd_question_mappings\n",
    "\n",
    "    records = {}\n",
    "    for filename in os.listdir(f'opinions_qa/output/{survey_name}/'):\n",
    "        if skip_exp(filename): continue\n",
    "\n",
    "        with open(f\"opinions_qa/output/{survey_name}/{filename}\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        exp = get_exp(filename)\n",
    "\n",
    "        res = []\n",
    "        pred_missing_cnt = 0\n",
    "        gold_missing_cnt = 0\n",
    "        for entry in data:\n",
    "            q_idx = entry['q_idx']\n",
    "            q_key = test_q_keys[q_idx]\n",
    "            pos_mapping = wd_question_mappings[q_key]\n",
    "            prediction = entry['prediction'].lower()\n",
    "            gold_answer = entry['gold_answer'].lower()\n",
    "            if gold_answer not in pos_mapping:\n",
    "                gold_missing_cnt += 1\n",
    "                continue\n",
    "            if prediction not in pos_mapping:\n",
    "                pred_missing_cnt += 1\n",
    "                if prediction not in entry['references']:\n",
    "                    refs = '/'.join(entry['references'].split('\\n'))\n",
    "                    print(f\"Prediction: |{prediction}|, Gold: |{gold_answer}|, References: |{refs}|\")\n",
    "                continue\n",
    "                prediction = random.choice(list(pos_mapping.keys()))\n",
    "            pred_pos = pos_mapping[prediction]\n",
    "            gold_pos = pos_mapping[gold_answer]\n",
    "            res.append(abs(pred_pos-gold_pos))\n",
    "        records[exp] = [Counter(res), np.mean(res), pred_missing_cnt, gold_missing_cnt]\n",
    "\n",
    "    q_wd_df = pd.DataFrame(records)\n",
    "    q_wd_df = q_wd_df[sorted(q_wd_df.columns)].transpose()\n",
    "    q_wd_df = q_wd_df.rename(columns={0: \"q_1wd_cnt\", 1: \"q_1wd\", 2: \"q_1wd_pmc\", 3: \"q_1wd_gmc\"})\n",
    "    q_wd_df\n",
    "\n",
    "    merged_df = pd.merge(acc_df, q_wd_df, left_index=True, right_index=True)\n",
    "    # merged_df = pd.merge(merged_df, s_wd_df, left_index=True, right_index=True)\n",
    "    # merged_df = merged_df[['wd_avg', 'wd_std', 'acc_avg', 'acc_std']]\n",
    "\n",
    "    merged_df = merged_df.sort_values(by='q_1wd', ascending=True)\n",
    "    merged_df = merged_df.sort_values(by='acc', ascending=False)\n",
    "\n",
    "    # merged_df.sort_values(by='acc_avg', ascending=False)\n",
    "    # merged_df.sort_values(by='wd_avg', ascending=True)\n",
    "    # merged_df = merged_df.sort_values(by='s_1wd', ascending=True)\n",
    "\n",
    "    merged_df['acc_cnt'] = merged_df['acc_cnt'].apply(lambda x: '\\''+str(x))\n",
    "    merged_df\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_Trends_Panel_W26\n",
      "['WORLDDANGER_W26', 'WORRYE_W26', 'GUN_W26', 'GUNIDENTITY_W26', 'GUNSOCIETY_W26', 'GUNCOMMUNITY_W26', 'GUNRESPKIDSC_W26']\n",
      "Prediction: |refused|, Gold: |positive way|, References: |Positive way/Negative way/Refused|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_cnt</th>\n",
       "      <th>acc</th>\n",
       "      <th>q_1wd_cnt</th>\n",
       "      <th>q_1wd</th>\n",
       "      <th>q_1wd_pmc</th>\n",
       "      <th>q_1wd_gmc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v13_prompt3_history</th>\n",
       "      <td>'=1511/2196</td>\n",
       "      <td>0.688069</td>\n",
       "      <td>{0.5: 82, 0.0: 1509, 1.0: 540, 2.0: 34, 3.0: 6}</td>\n",
       "      <td>0.307232</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v13_prompt3_history_demo_persona</th>\n",
       "      <td>'=1422/2207</td>\n",
       "      <td>0.644314</td>\n",
       "      <td>{0.5: 92, 0.0: 1420, 1.0: 619, 2.0: 37, 3.0: 13}</td>\n",
       "      <td>0.356717</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      acc_cnt       acc  \\\n",
       "v13_prompt3_history               '=1511/2196  0.688069   \n",
       "v13_prompt3_history_demo_persona  '=1422/2207  0.644314   \n",
       "\n",
       "                                                                         q_1wd_cnt  \\\n",
       "v13_prompt3_history                {0.5: 82, 0.0: 1509, 1.0: 540, 2.0: 34, 3.0: 6}   \n",
       "v13_prompt3_history_demo_persona  {0.5: 92, 0.0: 1420, 1.0: 619, 2.0: 37, 3.0: 13}   \n",
       "\n",
       "                                     q_1wd q_1wd_pmc q_1wd_gmc  \n",
       "v13_prompt3_history               0.307232         0        25  \n",
       "v13_prompt3_history_demo_persona  0.356717         1        25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for survey_name in survey_names:\n",
    "    print(survey_name)\n",
    "    merged = get_full_results(survey_name)\n",
    "    display(merged)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pump",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
